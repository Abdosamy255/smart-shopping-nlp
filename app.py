import os
import sys
import time
from datetime import datetime

import streamlit as st
import pandas as pd

from crawlir import crawl_amazon_to_csv  # ğŸ‘ˆ Ø¶ÙŠÙ Ø¯ÙŠ
from nlp.preprocessing import preprocess_text
from nlp.attribute_extraction import extract_attributes
from live_search import live_search,clean_price_amazon
from search.search_engine import search_products

#Ø¹Ø´Ø§Ù† ØªØ¸Ø¨Ø· Ø´ÙƒÙ„ Ø§Ù„Ø³Ø¹Ø±
def clean_price(x):
    if not isinstance(x, str):
        return pd.to_numeric(x, errors="coerce")

    x = x.replace("EGP", "").replace("Ø¬.Ù…", "").replace("Ø¬Ù†ÙŠÙ‡", "")
    x = x.replace(" Ø¬Ù†ÙŠÙ‡", "").replace("Ø±ÙŠØ§Ù„", "").strip()
    x = x.replace(" ", "")
    x = x.replace(",", "")
    x = re.sub(r"[^\d.]", "", x)

    val = pd.to_numeric(x, errors="coerce")
    try:
        if val.is_integer():
            return int(val)
        return val
    except:
        return val

# Ù„Ùˆ ÙÙŠ Ù…Ø´ÙƒÙ„Ø© imports Ù†Ø¶Ù…Ù† Ø¥Ù† Ø§Ù„Ø¬Ø°Ø± ÙÙŠ Ø§Ù„Ù€ path
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
if BASE_DIR not in sys.path:
    sys.path.insert(0, BASE_DIR)

from nlp.preprocessing import preprocess_text
from nlp.attribute_extraction import extract_attributes

# =========================
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
# =========================
st.set_page_config(
    page_title="Smart Shopping Assistant",
    page_icon="ğŸ›’",
    layout="wide"
)

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù€ session_state Ù„Ù„ØªØ§Ø±ÙŠØ®
if "history" not in st.session_state:
    st.session_state.history = []  # ÙƒÙ„ Ø¹Ù†ØµØ±: {"time", "query", "attrs", "count"}

# =========================
# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©
# =========================

def run_search(user_input: str):
    """NLP ÙÙ‚Ø·: ÙŠØ±Ø¬Ù‘Ø¹ tokens + attrs ÙˆÙ†Ø³ÙŠØ¨ Ø­ØªØ© Ø§Ù„Ø¨Ø­Ø« Ù„Ù„Ù€ live search."""
    tokens, lang, intents = preprocess_text(user_input)
    attrs = extract_attributes(tokens, lang)
    attrs["intents"] = intents
    return tokens, attrs


def apply_ui_filters(results: pd.DataFrame,
                     sort_by: str,
                     sort_dir: str,
                     max_price: float | None,
                     brand_filter: str | None):
    """ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„Ø§ØªØ± ÙˆØ§Ù„Ù€ sorting Ø¹Ù„Ù‰ DataFrame Ø§Ù„Ù†ØªØ§Ø¦Ø¬."""
    df = results.copy()

    # ÙÙ„ØªØ± Ø§Ù„Ø³Ø¹Ø±
    if max_price is not None and "price" in df.columns:
        df = df[df["price"] <= max_price]

    # ÙÙ„ØªØ± Ø§Ù„Ø¨Ø±Ø§Ù†Ø¯ (Ù„Ùˆ ÙÙŠÙ‡ Ø¹Ù…ÙˆØ¯ brand)
    if brand_filter and brand_filter.strip() and "brand" in df.columns:
        bf = brand_filter.strip().lower()
        df = df[df["brand"].fillna("").str.lower().str.contains(bf, na=False)]

    # ØªØ±ØªÙŠØ¨
    if sort_by and sort_by in df.columns:
        ascending = (sort_dir == "Ascending")
        df = df.sort_values(by=sort_by, ascending=ascending)

    return df
import re

def clean_price_column(df: pd.DataFrame) -> pd.DataFrame:
    if "price" not in df.columns:
        return df
    df = df.copy()
    df["price"] = (
        df["price"]
        .astype(str)
        .str.replace(r"[^\d]", "", regex=True)
        .replace("", None)
    )
    df["price"] = pd.to_numeric(df["price"], errors="coerce")
    return df.dropna(subset=["price"])


def render_product_card(row: pd.Series):
    """Ø¹Ø±Ø¶ ÙƒØ§Ø±Øª Ù…Ù†ØªØ¬ ÙˆØ§Ø­Ø¯ Ø¨Ù€ HTML Ø¨Ø³ÙŠØ·."""
    # ÙÙŠ Ø§Ù„Ù€ Live search Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ØºØ§Ù„Ø¨Ù‹Ø§: title, price, rating, image_url, product_link
    name = row.get("title", "Unknown product")
    price = row.get("price", "-")
    rating = row.get("rating", "-")
    link = row.get("product_link", "#")
    img = row.get("image_url", None)
    brand = row.get("brand", "-")

    left, right = st.columns([1, 3])

    with left:
        if isinstance(img, str) and img.strip():
            st.image(img, use_column_width=True)
        else:
            st.markdown(
                "<div style='width:100%;height:100px;border-radius:12px;"
                "background:linear-gradient(135deg,#00D09C33,#ffffff11);"
                "display:flex;align-items:center;justify-content:center;font-size:32px;'>ğŸ›</div>",
                unsafe_allow_html=True
            )

    with right:
        st.markdown(
            f"""
<div style="background:#1A1D23;padding:14px;border-radius:12px;margin-bottom:6px;">
  <div style="font-size:20px;font-weight:700;margin-bottom:4px;">{name}</div>
  <div>ğŸ”– <b>Brand:</b> {brand}</div>
  <div>ğŸ’² <b>Price:</b> {price} Ø¬Ù†ÙŠÙ‡</div>
  <div>â­ <b>Rating:</b> {rating}</div>
  <div style="margin-top:8px;">
    <a href="{link}" target="_blank"
       style="background:#00D09C;color:black;padding:6px 10px;border-radius:6px;
              text-decoration:none;font-weight:600;">
      Ø±Ø§Ø¨Ø· Ø§Ù„Ø´Ø±Ø§Ø¡
    </a>
  </div>
</div>
""",
            unsafe_allow_html=True
        )


# =========================
# Ø§Ù„Ù‡ÙŠØ¯Ø± Ø§Ù„Ø¹Ø§Ù…
# =========================

st.markdown(
    """
<style>
html, body, [class*="css"]  {
    font-family: "Segoe UI", "Cairo", sans-serif;
}
</style>
""",
    unsafe_allow_html=True,
)

st.markdown(
    """
<div style="text-align:center; font-size:40px; font-weight:700; margin-bottom:4px;">
ğŸ›’ Smart Shopping Assistant
</div>
<p style="text-align:center; color:#aaaaaa; margin-top:0;">
Arabic NLP â†’ Attribute Extraction â†’ Live Product Ranking from Amazon
</p>
<hr>
""",
    unsafe_allow_html=True,
)

# =========================
# Sidebar (ÙÙ„ØªØ±Ø© + Sorting)
# =========================

st.sidebar.header("âš™ï¸ Controls")

# Ø£Ù‚ØµÙ‰ Ø³Ø¹Ø±
max_price_val = st.sidebar.number_input(
    "Ø£Ù‚ØµÙ‰ Ø³Ø¹Ø± (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)",
    min_value=0,
    value=0,
    step=100
)
if max_price_val == 0:
    max_price_val = None
else:
    max_price_val = float(max_price_val)

# ÙÙ„ØªØ± Ø§Ù„Ø¨Ø±Ø§Ù†Ø¯ (ØªÙƒØ³Øª Ø­Ø± Ø¨Ø¯Ù„ Ù…Ø§ Ù†Ø¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ df_products)
brand_filter = st.sidebar.text_input(
    "ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø¨Ø±Ø§Ù†Ø¯ (Ù…Ø«Ø§Ù„: samsung, xiaomi)",
    value=""
).strip() or None

# Sorting options Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù€ live_search
sort_by = st.sidebar.selectbox(
    "ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨",
    options=["price", "rating", "title"],
    index=0
)
sort_dir = st.sidebar.radio("Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ØªØ±ØªÙŠØ¨", ["Ascending", "Descending"], index=0)

st.sidebar.markdown("---")
st.sidebar.write("âœ³ï¸ ÙƒÙ„ Ø¨Ø­Ø« Ø¬Ø¯ÙŠØ¯ Ø¨ÙŠØªØ³Ø¬Ù„ ÙÙŠ ØµÙØ­Ø© **History**.")

# =========================
# Tabs
# =========================

tab_search, tab_history, tab_about = st.tabs(["ğŸ” Search", "ğŸ•’ History", "â„¹ï¸ About"])

# ---------- TAB 1: Search ----------
with tab_search:
    st.markdown("### ğŸ” Ø§ÙƒØªØ¨ ÙˆØµÙ Ø§Ù„Ù…Ù†ØªØ¬")

    default_text = "Ø¹Ø§ÙŠØ² ÙƒÙˆØªØ´ Ø§Ø³ÙˆØ¯ Ù…Ù‚Ø§Ø³ 46 ØªØ­Øª 1500"
    user_input = st.text_area(
        "ÙˆØµÙ Ø§Ù„Ù…Ù†ØªØ¬",
        placeholder=default_text,
        height=80
    )

    search_clicked = st.button("ğŸš€ Ø§Ø¨Ø­Ø«", use_container_width=True)

if search_clicked:
    if not user_input.strip():
        st.warning("Ø§ÙƒØªØ¨ ÙˆØµÙ Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ø£ÙˆÙ„.")
    else:
        with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ ÙˆØ§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª..."):

            # 1) NLP: Preprocessing + Attributes (Ø¹Ø´Ø§Ù† Ù†Ø¹Ø±Ø¶Ù‡Ù… Ù„Ù„Ø¯ÙƒØªÙˆØ±)
            tokens, lang, intents = preprocess_text(user_input)
            attrs = extract_attributes(tokens, lang)
            attrs["intents"] = intents

            # 2) Ù†Ø¨Ù†ÙŠ Ø§Ù„Ù€ Query Ù…Ù† Ø§Ù„Ù€ tokens Ø¨Ø¹Ø¯ Ø§Ù„Ù€ preprocessing
            query = " ".join(tokens).strip()
            if not query:
                st.error("Ø¨Ø¹Ø¯ Ø§Ù„Ù€ preprocessing Ù…Ø§Ø¨Ù‚Ø§Ø´ ÙÙŠÙ‡ ÙƒÙ„Ù…Ø§Øª Ù…ÙÙŠØ¯Ø© ÙÙŠ Ø§Ù„Ù€ Query.")
                st.stop()

            # 3) Ù†Ù†Ø¯Ù‡ Ø§Ù„ÙƒØ±Ø§ÙˆÙ„Ø± Ø¹Ø´Ø§Ù† ÙŠÙƒØªØ¨ ÙÙŠ CSV
            csv_path = os.path.join("data", "live_amazon.csv")

            crawl_amazon_to_csv(
                query=query,
                output_path=csv_path,
                language="en",       # Ù„Ùˆ Ø­Ø§Ø¨Ø¨ ØªØ®Ù„ÙŠÙ‡Ø§ "ar" Ø£Ùˆ ØªÙ€ switch Ø­Ø³Ø¨ lang
                pages=1,
                detailed=False,
                max_products=30,
                append=False         # False = ÙƒÙ„ Ø¨Ø­Ø« ÙŠÙƒØªØ¨ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯
            )

            # 4) Ù†Ù‚Ø±Ø£ Ù…Ù† CSV
            try:
                raw_results = pd.read_csv(csv_path)
                raw_results['price'] = raw_results['price'].apply(clean_price_amazon)
                raw_results = raw_results.dropna(subset=['price'])
                

            except FileNotFoundError:
                st.error("Ù…Ù„Ù Ø§Ù„Ù€ CSV Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯ØŒ Ø­ØµÙ„Øª Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„ÙƒØ±Ø§ÙˆÙ„Ø±.")
                st.stop()

            # 5) Ù„Ùˆ Ø¹Ø§Ù…Ù„ÙŠÙ† search_query ÙÙŠ Ø§Ù„ÙƒØ±Ø§ÙˆÙ„Ø± Ù†ÙÙ„ØªØ± Ø¨ÙŠÙ‡ (Ù„Ùˆ Ø¶ÙØªÙ‡)
            if "search_query" in raw_results.columns:
                raw_results = raw_results[raw_results["search_query"] == query]

            # 6) ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø¹Ø±
            raw_results = clean_price_column(raw_results)

            # 7) Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¹Ø´Ø§Ù† ØªÙ…Ø´ÙŠ Ù…Ø¹ Ø§Ù„ÙƒØ±ÙˆØª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
            # Ø§Ù„ÙƒØ±Ø§ÙˆÙ„Ø± Ø¨ÙŠØ·Ù„Ø¹: title, price, rating, image, product_link
            # Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ÙƒØ§Ù†Øª Ù…ØªØ¹ÙˆØ¯Ø© Ø¹Ù„Ù‰: product_name, image_url, link
            results = raw_results.rename(
                columns={
                    "title": "product_name",
                    "image": "image_url",
                    "product_link": "link",
                }
            )
            # 8ï¸) Search + Ranking using NLP attributes
            final_results = search_products(
                results,
                attrs,
                top_n=50
            )

            time.sleep(0.3)


        # 9) Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ù€ history
        st.session_state.history.insert(
            0,
            {
                "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "query": user_input,
                "attrs": attrs,
                "count": int(len(final_results))
            }
        )

        # 10) Ø¹Ø±Ø¶ Ø§Ù„Ù€ Tokens Ùˆ Ø§Ù„Ù€ Attributes
        col_tokens, col_attrs = st.columns(2)
        with col_tokens:
            st.markdown("### ğŸ”¤ Tokens Ø¨Ø¹Ø¯ Ø§Ù„Ù€ Preprocessing")
            st.code(tokens)

        with col_attrs:
            st.markdown("### ğŸ§  Ø§Ù„Ø³Ù…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© (Attributes)")
            st.json(attrs)

        st.markdown("---")
        st.markdown("### ğŸ› Ø§Ù„Ù†ØªØ§Ø¦Ø¬")

        # 11) Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        if final_results.empty:
            st.info("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØµÙ ÙˆØ§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ø­Ø§Ù„ÙŠØ©.")
        else:
            st.success(f"ğŸ‘ ØªÙ… Ø¥ÙŠØ¬Ø§Ø¯ {len(final_results)} Ù†ØªÙŠØ¬Ø© Ø¨Ø¹Ø¯ Ø§Ù„ÙÙ„Ø§ØªØ±")

            # Cards
            top_cards = final_results.head(20)
            cols = st.columns(3)
            for i, (_, row) in enumerate(top_cards.iterrows()):
                with cols[i % 3]:
                    st.image(row.get("image_url", ""), width=120)
                    st.markdown(f"**{row.get('product_name','Ù…Ù†ØªØ¬ Ø¨Ø¯ÙˆÙ† Ø§Ø³Ù…')}**")
                    price = str(row['price'])

# Ù„Ùˆ Ù…ÙÙŠØ´ Ù†Ù‚Ø·Ø© ÙˆÙ†Ù‡Ø§ÙŠØ© Ø§Ù„Ø³Ø¹Ø± Ø±Ù‚Ù…ÙŠÙ†
                    if "." not in price and len(price) ==7:
                     price = price[:5] + "." + price[5:]

                     st.markdown(f"ğŸ’¸ {price} EGP")
                    elif "." not in price and len(price) ==6:
                     price = price[:4] + "." + price[4:]
                     st.markdown(f"ğŸ’¸ {price} EGP")
                    elif "." not in price and len(price) ==5:
                     price = price[:3] + "." + price[3:]
                     st.markdown(f"ğŸ’¸ {price} EGP")

                    

                    st.markdown(f"â­ {row.get('rating','-')}")
                    st.link_button("Ø¹Ø±Ø¶ Ø¹Ù„Ù‰ Amazon", row.get("link", "#"))
                    st.markdown("---")

            with st.expander("Ø¹Ø±Ø¶ ÙƒÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø¬Ø¯ÙˆÙ„"):
                st.dataframe(final_results.reset_index(drop=True))


# ---------- TAB 2: History ----------
with tab_history:
    st.markdown("### ğŸ•’ Search History")

    if not st.session_state.history:
        st.info("Ù„Ø³Ù‡ Ù…Ø§Ø¹Ù…Ù„ØªØ´ Ø£ÙŠ Ø¨Ø­Ø«.")
    else:
        for item in st.session_state.history:
            st.markdown(
                f"""
- **{item['time']}**  
  - Query: `{item['query']}`  
  - Results: **{item['count']}**  
  - Attributes: `{item['attrs']}`
"""
            )

        st.markdown("---")
        st.markdown("#### Summary Table")
        hist_df = pd.DataFrame(st.session_state.history)
        st.dataframe(hist_df)

        if st.button("ğŸ§¹ Ù…Ø³Ø­ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¨Ø§Ù„ÙƒØ§Ù…Ù„"):
            st.session_state.history = []
            st.experimental_rerun()

# ---------- TAB 3: About ----------
with tab_about:
    st.markdown("### â„¹ï¸ About Project")
    st.write(
        """
Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ù‡Ùˆ **Smart Shopping Assistant** Ù„Ù…Ø§Ø¯Ø© **NLP**:

- ÙŠÙÙ‡Ù… ÙˆØµÙ Ø§Ù„Ù…Ù†ØªØ¬ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ (Natural Language).
- ÙŠØ·Ø¨Ù‚ Ø®Ø·ÙˆØ§Øª Text Preprocessing:
  - Normalization
  - Tokenization
  - Stopwords Removal
- ÙŠØ³ØªØ®Ø±Ø¬ Ø§Ù„Ø³Ù…Ø§Øª (Attributes) Ù…Ø«Ù„:
  - Ù†ÙˆØ¹ Ø§Ù„Ù…Ù†ØªØ¬ (Product)
  - Ø§Ù„Ù„ÙˆÙ† (Color)
  - Ø§Ù„Ù…Ù‚Ø§Ø³ (Size)
  - Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© (Budget)
  - Ø§Ù„Ø¨Ø±Ø§Ù†Ø¯ (Brand)
- ÙŠØ³ØªØ®Ø¯Ù… Live Search Ù…Ù† Amazon Ø¹Ø¨Ø± Web Scraping (crawlir.py)
  Ø¨Ø¯Ù„ Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ù…Ù„Ù CSV Ø«Ø§Ø¨Øª.

ÙŠÙ…ÙƒÙ† ØªØ·ÙˆÙŠØ±Ù‡ Ù„Ø§Ø­Ù‚Ù‹Ø§ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… APIs Ø±Ø³Ù…ÙŠØ© Ø£Ùˆ Models Ø£Ù‚ÙˆÙ‰ (BERT, LLMs) Ø£Ùˆ Ø¯Ø¹Ù… Ù…ÙˆØ§Ù‚Ø¹ Ù…ØªØ¹Ø¯Ø¯Ø© (Jumia / Noon / Amazon).
"""
    )
    st.markdown("---")
    st.markdown("ğŸ‘¨â€ğŸ’» *Built by: Your Team (Third Year AI / NLP)*")
